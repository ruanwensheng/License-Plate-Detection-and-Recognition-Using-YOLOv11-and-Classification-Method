# Train and Deploy YOLO Models with Ultralytics to detect license plate
## üé• YOLOv8 Vehicle Detection Demo

![Demo](demo1.gif)


## Train YOLO Models With Google Colab

Click below to acces a Colab notebook for training YOLO models. It makes training a custom YOLO model as easy as uploading an image dataset and running a few blocks of code.

<a href="https://colab.research.google.com/github/ruanwensheng/License-Plate-Detection-Using-YOLOv11-/blob/main/License_Plate_Detection.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
## Results
![results](train/results.png)
### üîç Loss & Metric Curves

The model was trained for **15 epochs** with results shown below:

![Training Results](demo/results.png)

---

### ‚úÖ Observations (as an AI Engineer ‚Äì License Plate Detection)

| Criteria                     | Evaluation |
|-----------------------------|------------|
| **Training Trend**          | Stable and steadily decreasing across all losses. No major spikes or noise. |
| **Overfitting**             | Not observed. Validation loss closely follows training loss. |
| **Localization Accuracy**   | High: **mAP50 ‚âà 98.5%** |
| **General Detection Quality** | Good: **mAP50-95 ‚âà 72.5%**, still improvable for harder cases |
| **Precision**               | Increases consistently, reaching ~98.5% |
| **Recall**                  | Also increases well, reaching ~96.5% |
| **Fit for LPR Task**        | ‚úÖ Very suitable ‚Äì detects license plates consistently and accurately |

---

### üõ† Recommendations

- üìà Train for more epochs (e.g., +10‚Äì20) to see if mAP50-95 improves further.
- üéõ Use **advanced augmentations**: blur, low light, rotations, occlusion simulation.
- üß† Consider lightweight models (**YOLOv8n/s**) if targeting embedded or edge devices.

## Deploy YOLO Models
The `yolo_detect.py` script provides a basic example that shows how to load a model, run inference on an image source, parse the inference results, and display boxes around each detected class in the image. This script shows how to work with YOLO models in Python, and it can be used as a starting point for more advanced applications. 

To run inference with a yolov8s model on a USB camera at 1280x720 resolution, issue:

```
python yolo_detect.py --model yolov8s.pt --source usb0 --resolution 1280x720
```

Here are all the arguments for yolo_detect.py:

- `--model`: Path to a model file (e.g. `my_model.pt`). If the model isn't found, it will default to using `yolov8s.pt`.
- `--source`: Source to run inference on. The options are:
    - Image file (example: `test.jpg`)
    - Folder of images (example: `my_images/test`)
    - Video file (example: `testvid.mp4`)
    - Index of a connected USB camera (example: `usb0`)
    - Index of a connected Picamera module for Raspberry Pi (example: `picamera0`)
- `--thresh` (optional): Minimum confidence threshold for displaying detected objects. Default value is 0.5 (example: `0.4`)
- `--resolution` (optional): Resolution in WxH to display inference results at. If not specified, the program will match the source resolution. (example: `1280x720`)
- `--record` (optional): Record a video of the results and save it as `demo1.avi`. (If using this option, the `--resolution` argument must also be specified.)


### Deploy on Raspberry Pi
The Raspberry Pi 4 and 5 are just powerful enough to run nano and small-sized YOLO models in real time. The article linked below walks through how to run YOLO models on the Raspberry Pi.

[How to Run YOLO Detection Models on the Raspberry Pi](https://www.ejtech.io/learn/yolo-on-raspberry-pi)
